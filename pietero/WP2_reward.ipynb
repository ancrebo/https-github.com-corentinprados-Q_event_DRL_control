{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this Jupyter notebook, the data resulting from the ALYA simulation will determine the reward for the agents",
   "id": "c678f28c4fa45889"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "***\n",
    "\n",
    "# 0. Introduction \n",
    "\n",
    "***"
   ],
   "id": "a0398c923eef2760"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importation of useful libraries",
   "id": "b3f77ca4f16f1812"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:50:10.696203Z",
     "start_time": "2024-07-15T12:50:09.767299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET  # For XML parsing\n",
    "import pyvista as pv  # For reading and processing mesh data\n",
    "import pandas as pd  # For data manipulation and DataFrame creation\n",
    "import plotly.graph_objs as go  # For 3D interactive plot\n",
    "from plotly.subplots import make_subplots  # For 3D interactive plot\n",
    "from scipy.ndimage import label  # Function to count the number of clusters\n",
    "import plotly.express as px  # Package to color each clusters different\n",
    "from typing import Optional  # For type hinting\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ],
   "id": "ac227ad4f7f611f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:50:12.088951Z",
     "start_time": "2024-07-15T12:50:12.014489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Change Plotly renderer to browser instead of in notebook\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"browser\""
   ],
   "id": "13455d7ffae6e78b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Constants (Parameters)",
   "id": "22db00280219e0c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:56:08.877609Z",
     "start_time": "2024-07-15T12:56:08.873051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the units for the simulation\n",
    "height = 2.0\n",
    "Lx = 2.67*height  # Length in the x direction (unitless?)\n",
    "Ly = height  # Length in the y direction (unitless?)\n",
    "Lz = 0.8*height  # Length in the z direction (unitless?)\n",
    "\n",
    "n = 2  # Number of sections in the x direction\n",
    "m = 2  # Number of sections in the z direction\n",
    "\n",
    "H = 3  # Sensitivity threshold for Q-event detection\n",
    "\n",
    "\n",
    "# Path to the directory containing the simulation files\n",
    "directory_path = (\n",
    "    \"./baseline-coco-100TU/vtk/1end\"  # End of the longer run\n",
    ")\n",
    "\n",
    "# Path to the file containing pre-calculated averaged data\n",
    "averaged_data_path = \"baseline-coco-100TU/vtk/1end/averaged_data.parquet\"  # FOR EXAMPLE"
   ],
   "id": "74f896f194a8f608",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "***\n",
    "\n",
    "# 1. Data preparation \n",
    "\n",
    "***"
   ],
   "id": "879725ce9f39c249"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Loading Data\n",
    "Upon completion of the ALYA file translation, a VTK folder is generated. This folder contains a .PVD file, which facilitates the opening of the simulation in Paraview and provides timestep information. Additionally, multiple .PVTU files, accompanied by respective .VTU files, store the pertinent data."
   ],
   "id": "55f97ac3a59b2689"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:55:59.924880Z",
     "start_time": "2024-07-15T12:55:59.915538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data_and_convert_to_dataframe(directory):\n",
    "    \"\"\"\n",
    "    This function loads CFD simulation data from PVTU files and converts them into Pandas DataFrames.\n",
    "    Each DataFrame is stored along with its respective timestep, facilitating time-series analysis.\n",
    "\n",
    "    Parameters:\n",
    "    - directory (str): The path to the directory containing the PVD and PVTU files.\n",
    "\n",
    "    Returns:\n",
    "    - data_frames (list of tuples): A list where each element is a tuple containing:\n",
    "      * A timestep (float)\n",
    "      * A DataFrame with columns for spatial coordinates (x, y, z) and velocity components (U, V, W)\n",
    "    \"\"\"\n",
    "\n",
    "    # Parse the PVD file to extract mappings of timesteps to their corresponding PVTU files\n",
    "    pvd_path = os.path.join(directory, \"channel.pvd\")\n",
    "    tree = ET.parse(pvd_path)\n",
    "    root = tree.getroot()\n",
    "    timestep_file_map = {\n",
    "        dataset.attrib[\"file\"]: float(dataset.attrib[\"timestep\"])\n",
    "        for dataset in root.find(\"Collection\")\n",
    "    }\n",
    "\n",
    "    # List to store data tuples of timestep and DataFrame\n",
    "    data_frames = []\n",
    "\n",
    "    # Process each PVTU file according to its mapped timestep\n",
    "    for file, timestep in timestep_file_map.items():\n",
    "        path = os.path.join(directory, file)\n",
    "        mesh = pv.read(path)  # Read the mesh data from the PVTU file\n",
    "\n",
    "        # Extract the spatial coordinates and velocity components from the mesh\n",
    "        points = mesh.points  # x, y, z coordinates\n",
    "        U, V, W = mesh[\n",
    "            \"VELOC\"\n",
    "        ].T  # Transpose to separate the velocity components (U, V, W)\n",
    "\n",
    "        # Create a DataFrame with the extracted data\n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                \"x\": points[:, 0],\n",
    "                \"y\": points[:, 1],\n",
    "                \"z\": points[:, 2],\n",
    "                \"U\": U,\n",
    "                \"V\": V,\n",
    "                \"W\": W,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Append the timestep and DataFrame as a tuple to the list\n",
    "        data_frames.append((timestep, df))\n",
    "        print(f\"Data from {file} at timestep {timestep} loaded into DataFrame.\")\n",
    "\n",
    "    print(f\"Total data sets loaded: {len(data_frames)}\")\n",
    "    return data_frames"
   ],
   "id": "56004abfec7754c",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This predefined function is utilized to extract the data.",
   "id": "6b3578e7dce8f8a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:56:11.245257Z",
     "start_time": "2024-07-15T12:56:10.941929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the data and store it in `data`\n",
    "data = load_data_and_convert_to_dataframe(directory_path)\n",
    "\n",
    "# Print the number of rows for each timestep\n",
    "# for timestep, df in data:\n",
    "#     print(f\"Number of rows for timestep {timestep}: {len(df)}\")\n",
    "#     print(f\"Number of columns for timestep {timestep}: {len(df.columns)}\")\n",
    "\n",
    "# Print the first 20 rows of the first DataFrame to verify the data loading\n",
    "data[0][1].head(20)"
   ],
   "id": "56901fc884a9bce7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from channel_00040000.pvtu at timestep 120.238 loaded into DataFrame.\n",
      "Total data sets loaded: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "           x         y         z         U         V         W\n",
       "0   1.279375  0.005556  0.283333  0.298078 -0.020453  0.041378\n",
       "1   1.279375  0.005556  0.216667  0.317639 -0.025894 -0.008584\n",
       "2   1.279375  0.000000  0.283333  0.000000  0.000000  0.000000\n",
       "3   1.279375  0.000000  0.216667  0.000000  0.000000  0.000000\n",
       "4   1.056875  0.005556  0.283333  0.220093 -0.014425  0.027735\n",
       "5   1.056875  0.005556  0.216667  0.256658 -0.027676  0.028771\n",
       "6   1.056875  0.000000  0.283333  0.000000  0.000000  0.000000\n",
       "7   1.056875  0.000000  0.216667  0.000000  0.000000  0.000000\n",
       "8   1.223750  0.005556  0.283333  0.271646 -0.017845  0.020379\n",
       "9   1.223750  0.005556  0.216667  0.285931 -0.022400 -0.011715\n",
       "10  1.223750  0.000000  0.283333  0.000000  0.000000  0.000000\n",
       "11  1.223750  0.000000  0.216667  0.000000  0.000000  0.000000\n",
       "12  1.056875  0.005556  0.266667  0.227322 -0.021170  0.034321\n",
       "13  1.056875  0.003633  0.216667  0.212009 -0.020481  0.022648\n",
       "14  1.056875  0.000000  0.266667  0.000000  0.000000  0.000000\n",
       "15  1.056875  0.000000  0.233333  0.000000  0.000000  0.000000\n",
       "16  1.279375  0.005556  0.250000  0.306354 -0.026446  0.021899\n",
       "17  1.279375  0.000000  0.250000  0.000000  0.000000  0.000000\n",
       "18  1.168125  0.005556  0.283333  0.252571 -0.018874  0.013742\n",
       "19  1.168125  0.005556  0.216667  0.271478 -0.021268  0.002018"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>U</th>\n",
       "      <th>V</th>\n",
       "      <th>W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.279375</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.298078</td>\n",
       "      <td>-0.020453</td>\n",
       "      <td>0.041378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.279375</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.317639</td>\n",
       "      <td>-0.025894</td>\n",
       "      <td>-0.008584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.279375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.279375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.056875</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.220093</td>\n",
       "      <td>-0.014425</td>\n",
       "      <td>0.027735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.056875</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.256658</td>\n",
       "      <td>-0.027676</td>\n",
       "      <td>0.028771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.056875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.056875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.223750</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.271646</td>\n",
       "      <td>-0.017845</td>\n",
       "      <td>0.020379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.223750</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.285931</td>\n",
       "      <td>-0.022400</td>\n",
       "      <td>-0.011715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.223750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.223750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.056875</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.227322</td>\n",
       "      <td>-0.021170</td>\n",
       "      <td>0.034321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.056875</td>\n",
       "      <td>0.003633</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.212009</td>\n",
       "      <td>-0.020481</td>\n",
       "      <td>0.022648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.056875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.056875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.279375</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.306354</td>\n",
       "      <td>-0.026446</td>\n",
       "      <td>0.021899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.279375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.168125</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.252571</td>\n",
       "      <td>-0.018874</td>\n",
       "      <td>0.013742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.168125</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.271478</td>\n",
       "      <td>-0.021268</td>\n",
       "      <td>0.002018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Normalize the data based on channel dimensions",
   "id": "634aa2ed654bd215"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Scale/Normalize for each timestep, returning in same format as original data:\n",
    "- data_frames (list of tuples): A list where each element is a tuple containing:\n",
    "    * A timestep (float)\n",
    "    * A DataFrame with columns for spatial coordinates (x, y, z) and velocity components (U, V, W)"
   ],
   "id": "188a8926be22380d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:50:21.401803Z",
     "start_time": "2024-07-15T12:50:21.396307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize_data_frame(\n",
    "    df: pd.DataFrame, Lx: float, Ly: float, Lz: float\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Normalizes the spatial coordinates to the range [0, 1] based on their maximum values\n",
    "    and scales the velocity components by the corresponding channel lengths.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame with columns for spatial coordinates (x, y, z) and velocity components (U, V, W).\n",
    "    - Lx (float): Length in the x direction.\n",
    "    - Ly (float): Length in the y direction.\n",
    "    - Lz (float): Length in the z direction.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Scaled/Normalized DataFrame.\n",
    "    \"\"\"\n",
    "    # Copy the DataFrame to preserve original data\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Scale coordinates to 0-1 based on maximum respective coordinate value\n",
    "    df_copy[\"x\"] = df_copy[\"x\"] / df_copy[\"x\"].max()\n",
    "    df_copy[\"y\"] = df_copy[\"y\"] / df_copy[\"y\"].max()\n",
    "    df_copy[\"z\"] = df_copy[\"z\"] / df_copy[\"z\"].max()\n",
    "    df_copy[\"U\"] = df_copy[\"U\"] / df_copy[\"x\"].max()\n",
    "    df_copy[\"V\"] = df_copy[\"V\"] / df_copy[\"y\"].max()\n",
    "    df_copy[\"W\"] = df_copy[\"W\"] / df_copy[\"z\"].max()\n",
    "\n",
    "    # Normalize to channel dimensions so range is 0-Lx, 0-Ly, 0-Lz\n",
    "    df_copy[\"x\"] = df_copy[\"x\"] * Lx\n",
    "    df_copy[\"y\"] = df_copy[\"y\"] * Ly\n",
    "    df_copy[\"z\"] = df_copy[\"z\"] * Lz\n",
    "    df_copy[\"U\"] = df_copy[\"U\"] * Lx\n",
    "    df_copy[\"V\"] = df_copy[\"V\"] * Ly\n",
    "    df_copy[\"W\"] = df_copy[\"W\"] * Lz\n",
    "\n",
    "    return df_copy"
   ],
   "id": "b1164bce97c102e4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:56:15.684026Z",
     "start_time": "2024-07-15T12:56:15.659218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "data_normalized = []\n",
    "\n",
    "for timestep, df in data:\n",
    "    # append the normalized data to the list, including timestep information like the original format\n",
    "    data_normalized.append((timestep, normalize_data_frame(df, Lx, Ly, Lz)))\n",
    "    print(f\"Data normalized for timestep {timestep}.\")\n",
    "    \n",
    "# Print the first 20 rows of the first DataFrame to verify the data normalization\n",
    "# data_normalized[0][1].head(20)"
   ],
   "id": "d2006fcb341a712f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data normalized for timestep 120.238.\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "***\n",
    "# 2. Data Processing\n",
    "***"
   ],
   "id": "dcdd571b90bc0209"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Velocity fields definitions\n",
    "\n",
    "The following table summarizes the key velocity fields used in fluid dynamics, highlighting their formulas and roles:\n",
    "\n",
    "| Symbol | Description | Definition | Role |\n",
    "|--------|-------------|------------|------|\n",
    "| $U(x,y,z,t)$ | Instantaneous velocity field | Represents the velocity at each point $(x, y, z)$ and any time $t$. | Captures detailed fluid dynamics at each point and time. |\n",
    "| $\\overline{U}(y)$ | Averaged velocity field | Averaged over $x$, $z$, and $t$ | Simplifies the 4D field to a function of $y$, smoothing out other variations. |\n",
    "| $u(x,y,z,t)$ | Velocity fluctuation field | $U(x,y,z,t) - \\overline{U}(y)$ | Measures local deviations from the mean, critical for analyzing turbulence. |\n",
    "| $u'(y)$ | RMS velocity fluctuations | RMS of $u(x,y,z,t)$ across a given dataset | Quantifies the intensity of turbulence or variability along $y$. |\n",
    "\n",
    "The vertical ($V$ and $v$) and lateral ($W$ and $w$) components of the velocity are defined analogously to the horizontal components ($U$ and $u$).\n",
    "\n",
    "\n",
    "The upcoming code will compute all these values using the same notation and methods as described."
   ],
   "id": "7a16898700b92357"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:50:26.543662Z",
     "start_time": "2024-07-15T12:50:26.536818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_velocity_data_multiple_timesteps(data, N):\n",
    "    \"\"\"\n",
    "    Processes a list of tuples containing CFD simulation data to calculate averaged and\n",
    "    fluctuating components of velocity fields over the last N entries. It computes these metrics for\n",
    "    the horizontal (U), vertical (V), and lateral (W) velocity components.\n",
    "\n",
    "    Parameters:\n",
    "    - data (list of tuples): Each tuple contains a timestep and a DataFrame with spatial coordinates (x, y, z)\n",
    "      and velocity components (U, V, W).\n",
    "    - N (int): Number of most recent timesteps to include in the averaging process.\n",
    "\n",
    "    Returns:\n",
    "    - averaged_data (DataFrame): Contains averaged velocities ($\\overline{U}(y)$, $\\overline{V}(y)$, $\\overline{W}(y)$)\n",
    "      and rms of velocity fluctuations ($u'(y)$, $v'(y)$, $w'(y)$) as columns, indexed by the y-coordinate.\n",
    "    - data_process (list of tuples): Each tuple contains a timestep and a DataFrame with original and fluctuating\n",
    "      velocity components (U, V, W, u, v, w).\n",
    "    \"\"\"\n",
    "    processed_data = []\n",
    "    recent_data = pd.DataFrame()\n",
    "\n",
    "    # Aggregate data from the last N timesteps to compute averages and fluctuations\n",
    "    for timestep, df in data[-N:]:\n",
    "        df[\"timestep\"] = timestep  # Temporarily add timestep to differentiate data\n",
    "        recent_data = pd.concat([recent_data, df], ignore_index=True)\n",
    "\n",
    "    # Calculate mean and standard deviation for u, v, w across the recent data\n",
    "    averaged_data = (\n",
    "        recent_data.groupby(\"y\")\n",
    "        .agg({\"U\": [\"mean\", \"std\"], \"V\": [\"mean\", \"std\"], \"W\": [\"mean\", \"std\"]})\n",
    "        .rename(columns={\"mean\": \"bar\", \"std\": \"prime\"}, level=1)\n",
    "    )\n",
    "    averaged_data.columns = [\n",
    "        \"U_bar\",\n",
    "        \"u_prime\",\n",
    "        \"V_bar\",\n",
    "        \"v_prime\",\n",
    "        \"W_bar\",\n",
    "        \"w_prime\",\n",
    "    ]  # Clear column names\n",
    "\n",
    "    # Process each individual dataset for detailed fluctuation analysis\n",
    "    for timestep, df in data:\n",
    "        y_means = averaged_data.loc[df[\"y\"]]\n",
    "        df_processed = df.copy()\n",
    "        df_processed[\"U\"] = df[\"U\"]\n",
    "        df_processed[\"V\"] = df[\"V\"]\n",
    "        df_processed[\"W\"] = df[\"W\"]\n",
    "        df_processed[\"u\"] = df[\"U\"] - y_means[\"U_bar\"].values\n",
    "        df_processed[\"v\"] = df[\"V\"] - y_means[\"V_bar\"].values\n",
    "        df_processed[\"w\"] = df[\"W\"] - y_means[\"W_bar\"].values\n",
    "\n",
    "        # Ensure no 'timestep' column remains in the output data\n",
    "        df_processed.drop(columns=\"timestep\", inplace=True, errors=\"ignore\")\n",
    "        processed_data.append((timestep, df_processed))\n",
    "\n",
    "    # Prepare averaged data for output\n",
    "    averaged_data = averaged_data.reset_index()\n",
    "\n",
    "    return averaged_data, processed_data"
   ],
   "id": "f55e35350b8b5022",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Note : Here we do the average over the all data because it is only the end of the simulation.\n",
    "But it is important to not take the transitional state for the averaging"
   ],
   "id": "e6fd53428f29b26a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:56:20.062526Z",
     "start_time": "2024-07-15T12:56:19.991955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "N = 1  # Averaging over the last N timesteps\n",
    "# Note : Here we do the average over the all data because it is only the 1end of the simulation.\n",
    "# But it is important to not take the transitional state for the averaging\n",
    "averaged_data, data_process = process_velocity_data_multiple_timesteps(data_normalized, N)"
   ],
   "id": "82010a03a1b6fa8",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## (FOR UBAR ONLY) Save Averaged Data as .pkl file",
   "id": "7b4df51623839960"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:56:23.019834Z",
     "start_time": "2024-07-15T12:56:23.017091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_dataframe_to_parquet(df: pd.DataFrame, file_path: str):\n",
    "    \"\"\"\n",
    "    Save a DataFrame to a Parquet file.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame to save.\n",
    "    - file_path (str): The path to the file where the DataFrame should be saved.\n",
    "    \"\"\"\n",
    "    df.to_parquet(file_path, index=None)"
   ],
   "id": "4d5da95a99bfbcec",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "#averaged_data.head()",
   "id": "fabee240a4583434",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:56:35.387064Z",
     "start_time": "2024-07-15T12:56:35.370212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the averaged data to a Parquet file for future use\n",
    "save_dataframe_to_parquet(averaged_data, averaged_data_path)"
   ],
   "id": "c6f895736f2b216",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:56:51.952240Z",
     "start_time": "2024-07-15T12:56:51.942109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test for loading saved parquet file\n",
    "averaged_data_LOADED = pd.read_parquet(averaged_data_path)\n",
    "\n",
    "# averaged_data_LOADED.head()"
   ],
   "id": "9594bb3513523460",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Display the first 20 rows of the processed data\n",
    "# data_process[0][1].head(20)"
   ],
   "id": "147e39ae81ea6924",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "***\n",
    "# 3. Q-events dectection \n",
    "***"
   ],
   "id": "ceff0e8983f54ccf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Explanation\n",
    "\n",
    "### Objectives and Computational Tools Overview\n",
    "\n",
    "This section is dedicated to advancing our understanding of turbulent flow dynamics through the identification and analysis of Q-events. The aims of this analysis are threefold:\n",
    "\n",
    "1. **Q-event Detection**: To accurately identify grid points exhibiting Q-events, which represent significant local interactions in fluid dynamics.\n",
    "2. **Cluster Analysis**: Upon detection, to quantify these points by clustering, as referenced in the literature under Q-events. This process involves grouping connected Q-events to understand their collective behavior.\n",
    "3. **Optimization of Sensitivity Threshold (H)**: To determine the value of \\(H\\) that maximizes the number of Q-event clusters for a given dataset. This parameter tuning is critical for enhancing the detection algorithm's sensitivity and accuracy.\n",
    "\n",
    "#### Visualization Tools\n",
    "\n",
    "To facilitate these analyses, several visualization functions have been developed, each corresponding to a specific objective:\n",
    "\n",
    "- **Q-event Distribution Visualization**: This function allows for the comprehensive visualization of all Q-event points for a selected timestep, providing a macroscopic view of event distributions.\n",
    "- **Cluster Visualization**: A dedicated function to display Q-events grouped by clusters, aiding in the microscopic examination of the spatial structure and extent of these events.\n",
    "- **Percolation Diagram**: This function plots the percolation curve, which represents the number of clusters as a function of \\(H\\). It serves to illustrate how variations in \\(H\\) influence the clustering behavior, guiding the optimal selection of this threshold.\n",
    "\n",
    "#### Summary of Functions\n",
    "\n",
    "The following table encapsulates the functions developed for this analysis, detailing their specific applications and outputs:\n",
    "\n",
    "| Function Name            | Parameters                                                                                   | Returns                                                                         |\n",
    "|--------------------------|----------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------|\n",
    "| `detect_Q_events`        | `processed_data`: List of tuples, `averaged_data`: DataFrame, `H`: float                     | List of tuples, each containing a timestep and a DataFrame with Q event flags  |\n",
    "| `plot_Q_events_3d`       | `df`: DataFrame containing columns ['x', 'y', 'z', 'Q']                                      | None, plots an interactive 3D scatter plot highlighting Q events                |\n",
    "| `count_q_clusters`       | `q_event`: DataFrame containing columns ['x', 'y', 'z', 'Q']                                 | Integer, number of distinct clusters in 3D space                                |\n",
    "| `plot_3d_clusters`       | `q_event`: DataFrame containing columns ['x', 'y', 'z', 'Q']                                 | None, plots an interactive 3D visualization of clusters                         |\n",
    "| `analyze_q_clusters`     | `processed_data`: List of tuples, `averaged_data`: DataFrame                                 | List of tuples, each containing an H value and the mean number of clusters      |\n",
    "| `plot_percolation_diagram` | `cluster_analysis_results`: List of tuples                                                   | None, prints and plots the percolation diagram showing the cluster density vs H |\n",
    "\n",
    "These tools are integral to the methodological exploration of turbulence characteristics and provide crucial insights into the dynamics of turbulent flows.\n",
    "\n",
    "#### Q-events definition\n",
    "\n",
    "Q events help identify regions with significant interactions between fluctuating velocities. The detection criterion is as follows:\n",
    "\n",
    "| Condition | Description | Threshold |\n",
    "|-----------|-------------|-----------|\n",
    "| $|u(x,y,z,t) \\cdot v(x,y,z,t)| \\geq H \\cdot u'(y) \\cdot v'(y)$ | Detects Q events | The product of fluctuating velocities exceeds $H$ times the product of their RMS values, where $H$ will is determined by maximising the number of Q-events detected. |"
   ],
   "id": "be062ca9434e83f1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3a. Detection of Q-events for each time step",
   "id": "7bccbb8da7df9212"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:51:38.905711Z",
     "start_time": "2024-07-15T12:51:38.900863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def detect_Q_events(processed_data, averaged_data, H):\n",
    "    \"\"\"\n",
    "    Detects Q events in the fluid dynamics data based on the specified condition.\n",
    "\n",
    "    Parameters:\n",
    "    - processed_data (list of tuples): Data processed by `process_velocity_data_multiple_timesteps`, containing:\n",
    "      * A timestep (float)\n",
    "      * A DataFrame with spatial coordinates (x, y, z) and velocity components U, V, W, u, v, w\n",
    "    - averaged_data (DataFrame): Data containing the rms values for velocity components u and v for each y coordinate. **(u' and v')**\n",
    "    - H (float): The sensitivity threshold for identifying Q events.\n",
    "\n",
    "    Returns:\n",
    "    - data_frames (list of tuples): Each tuple contains:\n",
    "      * A timestep (float)\n",
    "      * A DataFrame with columns ['x', 'y', 'z', 'Q'], where 'Q' is a boolean indicating whether a Q event is detected.\n",
    "    \"\"\"\n",
    "    q_event_data = []\n",
    "\n",
    "    for timestep, df in processed_data:\n",
    "        # Fetch the rms values for 'u' and 'v' based on y-coordinate\n",
    "        rms_values = (\n",
    "            averaged_data.set_index(\"y\")[[\"u_prime\", \"v_prime\"]].reindex(df[\"y\"]).values\n",
    "        )\n",
    "\n",
    "        # Calculate the product of fluctuating components u and v\n",
    "        uv_product = np.abs(df[\"u\"] * df[\"v\"])\n",
    "\n",
    "        # Calculate the threshold product of rms values u' and v'\n",
    "        threshold = H * rms_values[:, 0] * rms_values[:, 1]\n",
    "\n",
    "        # Determine where the Q event condition is met\n",
    "        # q_events = uv_product >= threshold\n",
    "        q_events = uv_product > threshold  # to avoid detect on 0\n",
    "\n",
    "        # Create DataFrame with Q event boolean flag\n",
    "        q_df = pd.DataFrame({\"x\": df[\"x\"], \"y\": df[\"y\"], \"z\": df[\"z\"], \"Q\": q_events})\n",
    "\n",
    "        q_event_data.append((timestep, q_df))\n",
    "\n",
    "    return q_event_data"
   ],
   "id": "10cdc491224ea6f4",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:56:55.719061Z",
     "start_time": "2024-07-15T12:56:55.700664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Here is an example of the use \n",
    "Q_event_frames = detect_Q_events(data_process, averaged_data_LOADED, H)"
   ],
   "id": "d346c4dc80e3b4a5",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3b. Plot for a particular time step",
   "id": "c1a0c96eb1163711"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:51:49.922309Z",
     "start_time": "2024-07-15T12:51:49.916804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_Q_events_3d(df):\n",
    "    \"\"\"\n",
    "    Plot an interactive 3D scatter of the points, highlighting the surface where Q is True.\n",
    "\n",
    "    Parameters:\n",
    "    - df (DataFrame): DataFrame containing columns ['x', 'y', 'z', 'Q'], where 'Q' is a boolean.\n",
    "    \"\"\"\n",
    "    # Create a figure with plotly\n",
    "    fig = make_subplots(rows=1, cols=1, specs=[[{\"type\": \"scatter3d\"}]])\n",
    "\n",
    "    # Filter points where Q is True and False\n",
    "    df_true = df[df[\"Q\"]]\n",
    "    df_false = df[~df[\"Q\"]]\n",
    "\n",
    "    # Add scatter plot for points where Q is False\n",
    "    trace_false = go.Scatter3d(\n",
    "        x=df_false[\"x\"],\n",
    "        y=df_false[\"z\"],\n",
    "        z=df_false[\"y\"],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(\n",
    "            size=3, color=\"blue\", opacity=0.5  # marker color  # marker opacity\n",
    "        ),\n",
    "        name=\"Q=False\",\n",
    "    )\n",
    "\n",
    "    # Add scatter plot for points where Q is True\n",
    "    trace_true = go.Scatter3d(\n",
    "        x=df_true[\"x\"],\n",
    "        y=df_true[\"z\"],\n",
    "        z=df_true[\"y\"],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(size=3, color=\"red\", opacity=0.5),  # marker color  # marker opacity\n",
    "        name=\"Q=True\",\n",
    "    )\n",
    "\n",
    "    # Add traces to the figure\n",
    "    # fig.add_trace(trace_false, row=1, col=1)\n",
    "    fig.add_trace(trace_true, row=1, col=1)\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=\"3D Scatter Plot of Q Events\",\n",
    "        scene=dict(\n",
    "            xaxis_title=\"X Coordinate\",\n",
    "            yaxis_title=\"Z Coordinate\",\n",
    "            zaxis_title=\"Y Coordinate\",\n",
    "        ),\n",
    "        legend_title=\"Legend\",\n",
    "        height=700,\n",
    "        width=800,\n",
    "    )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show(renderer=\"browser\")"
   ],
   "id": "2ec060d103b682",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:57:00.592602Z",
     "start_time": "2024-07-15T12:56:59.608889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Timestep of the Q-event to plot\n",
    "num_timestep = 0\n",
    "# The Q-event\n",
    "Q_event = Q_event_frames[num_timestep][1]\n",
    "# Plot\n",
    "plot_Q_events_3d(Q_event)"
   ],
   "id": "e208e100111f523e",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3c. Count the local number of Q-events",
   "id": "f117f55a47bfa920"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T12:59:50.741205Z",
     "start_time": "2024-07-15T12:59:50.733878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_local_Q_ratios(\n",
    "    df: pd.DataFrame, n: int, m: int, Lx: float, Lz: float, verbose: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the ratio of Q-events in local volumes for a single timestep.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame with columns ['x', 'y', 'z', 'Q'].\n",
    "    - n (int): Number of sections in the x direction.\n",
    "    - m (int): Number of sections in the z direction.\n",
    "    - Lx (float): Length in the x direction.\n",
    "    - Lz (float): Length in the z direction.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with columns ['x_index', 'z_index', 'Q_event_count', 'total_points', 'Q_ratio'].\n",
    "    \"\"\"\n",
    "    # Step sizes for local volumes\n",
    "    step_x = Lx / n\n",
    "    step_z = Lz / m\n",
    "    if verbose:\n",
    "        print(f\"step_x = {step_x}\")\n",
    "        print(f\"step_z = {step_z}\")\n",
    "\n",
    "    # Initialize list to collect results\n",
    "    results = []\n",
    "\n",
    "    # Loop through each local volume\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            # Calculate the boundaries of the local volume\n",
    "            x_min = i * step_x\n",
    "            x_max = (i + 1) * step_x\n",
    "            z_min = j * step_z\n",
    "            z_max = (j + 1) * step_z\n",
    "\n",
    "            # Filter points within this local volume\n",
    "            local_points = df[\n",
    "                (df[\"x\"] >= x_min)\n",
    "                & (df[\"x\"] < x_max)\n",
    "                & (df[\"z\"] >= z_min)\n",
    "                & (df[\"z\"] < z_max)\n",
    "            ]\n",
    "\n",
    "            # Calculate counts and Q ratio\n",
    "            total_points = len(local_points)\n",
    "            Q_event_count = local_points[\"Q\"].sum()\n",
    "            Q_ratio = Q_event_count / total_points if total_points > 0 else 0\n",
    "\n",
    "            # Append results\n",
    "            results.append(\n",
    "                {\n",
    "                    \"x_index\": i,\n",
    "                    \"z_index\": j,\n",
    "                    \"Q_event_count\": Q_event_count,\n",
    "                    \"total_points\": total_points,\n",
    "                    \"Q_ratio\": Q_ratio,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"\\nlocal volume {i, j}\")\n",
    "                print(f\"local volume {i, j} x_min {x_min}\")\n",
    "                print(f\"local volume {i, j} x_max {x_max}\")\n",
    "                print(f\"local volume {i, j} z_min {z_min}\")\n",
    "                print(f\"local volume {i, j} z_max {z_max}\\n\")\n",
    "                # print coordinates of every 1000th point in the local volume\n",
    "                print(\n",
    "                    f\"local volume {i, j} every 1000th filtered point:\\n {local_points[::1000]}\\n\"\n",
    "                )\n",
    "                # print every 500th coordinate in filtered points with Q event\n",
    "                print(\n",
    "                    f\"local volume {i, j} every 500th filtered point with Q event:\\n {local_points[local_points['Q']].iloc[::500]}\\n\"\n",
    "                )\n",
    "                print(f\"local volume {i, j} total_points {total_points}\")\n",
    "                print(f\"local volume {i, j} Q_event_count {Q_event_count}\")\n",
    "                print(f\"local volume {i, j} Q_ratio {Q_ratio}\\n\")\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    result_df = pd.DataFrame(results)\n",
    "\n",
    "    return result_df\n"
   ],
   "id": "49508894eb8fad85",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T13:00:05.266303Z",
     "start_time": "2024-07-15T13:00:05.249086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "# Process each Q_event_frame individually\n",
    "verbose = False  # Set to True to display additional information for each local volume\n",
    "all_results = []\n",
    "\n",
    "for timestep, df in Q_event_frames:\n",
    "    result_df = calculate_local_Q_ratios(df, n, m, Lx, Lz, verbose=verbose)\n",
    "    result_df[\"timestep\"] = timestep  # Add the timestep for context\n",
    "    all_results.append(result_df)\n",
    "\n",
    "# Combine all results into a single DataFrame\n",
    "final_result_df = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "# Print the total number of local volumes and total points in each local volume\n",
    "total_local_volumes = n * m\n",
    "if verbose:\n",
    "    print(f\"Total number of local volumes: {total_local_volumes}\")\n",
    "\n",
    "# Calculate total points in each local volume for the first timestep\n",
    "first_timestep_df = all_results[0]\n",
    "unique_local_volumes = first_timestep_df[[\"x_index\", \"z_index\"]].drop_duplicates()\n",
    "\n",
    "for _, volume in unique_local_volumes.iterrows():\n",
    "    x_index = volume[\"x_index\"]\n",
    "    z_index = volume[\"z_index\"]\n",
    "    points_in_volume = first_timestep_df[\n",
    "        (first_timestep_df[\"x_index\"] == x_index)\n",
    "        & (first_timestep_df[\"z_index\"] == z_index)\n",
    "    ][\"total_points\"].values[0]\n",
    "    print(f\"Local volume ({x_index}, {z_index}) has {points_in_volume} total points.\")"
   ],
   "id": "28edcef595b5cfb7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local volume (0, 0) has 115482 total points.\n",
      "Local volume (0, 1) has 120067 total points.\n",
      "Local volume (1, 0) has 121624 total points.\n",
      "Local volume (1, 1) has 124158 total points.\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3c-1. Additional analysis of local volumes",
   "id": "2689c34cdab5850"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T13:00:12.654353Z",
     "start_time": "2024-07-15T13:00:12.646627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_local_Q_event_number_bar(\n",
    "    timestep_data: pd.DataFrame, n: int, m: int, timestep: Optional[float] = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plots the total and Q event points for each local volume/agent.\n",
    "\n",
    "    Parameters:\n",
    "    - timestep_data (pd.DataFrame): DataFrame containing local volume data for the specified timestep.\n",
    "    - n (int): Number of sections in the x direction.\n",
    "    - m (int): Number of sections in the z direction.\n",
    "    - timestep (Optional[float]): The specific timestep to plot. If None, it will be ignored in the title.\n",
    "    \"\"\"\n",
    "    # Extract data for the 3D bar chart\n",
    "    x_indices = timestep_data[\"x_index\"] + 0.5  # Offset by 0.5 to center the bars\n",
    "    z_indices = timestep_data[\"z_index\"] + 0.5  # Offset by 0.5 to center the bars\n",
    "    total_points = timestep_data[\"total_points\"]\n",
    "    Q_event_points = timestep_data[\"Q_event_count\"]\n",
    "\n",
    "    # Create 3D bars\n",
    "    bars = []\n",
    "    # Bars for total points\n",
    "    for x, z, points in zip(x_indices, z_indices, total_points):\n",
    "        bars.append(\n",
    "            go.Scatter3d(\n",
    "                x=[x - 0.1, x - 0.1],  # Slight offset\n",
    "                y=[z, z],\n",
    "                z=[0, points],\n",
    "                mode=\"lines\",\n",
    "                line=dict(color=\"blue\", width=10),\n",
    "                name=\"Total Points\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Bars for Q-event points\n",
    "    for x, z, points in zip(x_indices, z_indices, Q_event_points):\n",
    "        bars.append(\n",
    "            go.Scatter3d(\n",
    "                x=[x + 0.1, x + 0.1],  # Slight offset\n",
    "                y=[z, z],\n",
    "                z=[0, points],\n",
    "                mode=\"lines\",\n",
    "                line=dict(color=\"red\", width=10),\n",
    "                name=\"Q-event Points\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    title = f\"Total Points and Q-event Points\"\n",
    "    if timestep is not None:\n",
    "        title += f\" for Timestep {timestep}\"\n",
    "\n",
    "    fig = go.Figure(data=bars)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        scene=dict(\n",
    "            xaxis=dict(\n",
    "                title=\"X Index\",\n",
    "                range=[0, n],\n",
    "                tickvals=list(range(n + 1)),  # Set gridlines to integer values\n",
    "                showgrid=True,\n",
    "                gridcolor=\"lightgrey\",\n",
    "            ),\n",
    "            yaxis=dict(\n",
    "                title=\"Z Index\",\n",
    "                range=[0, m],\n",
    "                tickvals=list(range(m + 1)),  # Set gridlines to integer values\n",
    "                showgrid=True,\n",
    "                gridcolor=\"lightgrey\",\n",
    "            ),\n",
    "            zaxis=dict(title=\"Points\", showgrid=True, gridcolor=\"lightgrey\"),\n",
    "        ),\n",
    "        showlegend=False,  # Show legend separately\n",
    "        height=800,  # Set the height of the figure\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ],
   "id": "d08ad156d5c5b3b1",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T13:00:31.154777Z",
     "start_time": "2024-07-15T13:00:30.608825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "verbose_local_volume = (\n",
    "    False  # Set to True to display additional information for each local volume\n",
    ")\n",
    "\n",
    "# Process each Q_event_frame individually and collect results in a dictionary\n",
    "results_by_timestep = {}\n",
    "\n",
    "for timestep, df in Q_event_frames:\n",
    "    result_df = calculate_local_Q_ratios(df, n, m, Lx, Lz, verbose=verbose_local_volume)\n",
    "    results_by_timestep[timestep] = result_df\n",
    "\n",
    "# Select the specific timestep you want to plot\n",
    "timestep_to_plot_index = 0  # Index of the timestep to plot\n",
    "timestep_to_plot = list(results_by_timestep.keys())[timestep_to_plot_index]\n",
    "# timestep_to_plot = 895.2  # Specify the timestep you want to plot\n",
    "timestep_data = results_by_timestep[timestep_to_plot]\n",
    "\n",
    "if verbose_local_volume:\n",
    "    print(f\"n = {n}, m = {m}, Lx = {Lx}, Ly = {Ly}, Lz = {Lz}\")\n",
    "\n",
    "    # Print the total number of local volumes\n",
    "    total_local_volumes = n * m\n",
    "    print(f\"Total number of local volumes: {total_local_volumes}\\n\")\n",
    "\n",
    "    # Additional print statements for the selected timestep\n",
    "    min_total_points = timestep_data[\"total_points\"].min()\n",
    "    max_total_points = timestep_data[\"total_points\"].max()\n",
    "    avg_total_points = timestep_data[\"total_points\"].mean()\n",
    "    std_dev_total_points = timestep_data[\"total_points\"].std()\n",
    "    percent_deviation_total_points = (std_dev_total_points / avg_total_points) * 100\n",
    "\n",
    "    min_Q_event_points = timestep_data[\"Q_event_count\"].min()\n",
    "    max_Q_event_points = timestep_data[\"Q_event_count\"].max()\n",
    "    avg_Q_event_points = timestep_data[\"Q_event_count\"].mean()\n",
    "    std_dev_Q_event_points = timestep_data[\"Q_event_count\"].std()\n",
    "    percent_deviation_Q_event_points = (\n",
    "        std_dev_Q_event_points / avg_Q_event_points\n",
    "    ) * 100\n",
    "\n",
    "    print(f\"List of all timesteps: {list(results_by_timestep.keys())}\\n\")\n",
    "    print(f\"Selected timestep: {timestep_to_plot}\\n\")\n",
    "    print(f\"Minimum number of total points per local volume: {min_total_points}\")\n",
    "    print(f\"Maximum number of total points per local volume: {max_total_points}\")\n",
    "    print(f\"Average number of total points per local volume: {avg_total_points}\")\n",
    "    print(\n",
    "        f\"Standard deviation of total points per local volume: {std_dev_total_points}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Percent deviation of total points per local volume: {percent_deviation_total_points:.2f}%\\n\"\n",
    "    )\n",
    "\n",
    "    print(f\"Minimum number of Q-event points per local volume: {min_Q_event_points}\")\n",
    "    print(f\"Maximum number of Q-event points per local volume: {max_Q_event_points}\")\n",
    "    print(f\"Average number of Q-event points per local volume: {avg_Q_event_points}\")\n",
    "    print(\n",
    "        f\"Standard deviation of Q-event points per local volume: {std_dev_Q_event_points}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Percent deviation of Q-event points per local volume: {percent_deviation_Q_event_points:.2f}%\\n\"\n",
    "    )\n",
    "\n",
    "plot_local_Q_event_number_bar(timestep_data, n, m)\n"
   ],
   "id": "941ff68c1fc620e2",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T13:00:38.857697Z",
     "start_time": "2024-07-15T13:00:38.841198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_local_Q_events_3d(\n",
    "    df: pd.DataFrame,\n",
    "    n: int,\n",
    "    m: int,\n",
    "    Lx: float,\n",
    "    Ly: float,\n",
    "    Lz: float,\n",
    "    local_x_index: int,\n",
    "    local_z_index: int,\n",
    "    switch_y_z: bool = True,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot an interactive 3D scatter of the points, highlighting the Q-event points in a specified local volume.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame containing columns ['x', 'y', 'z', 'Q'], where 'Q' is a boolean.\n",
    "    - n (int): Number of sections in the x direction.\n",
    "    - m (int): Number of sections in the z direction.\n",
    "    - Lx (float): Length in the x direction.\n",
    "    - Ly (float): Length in the y direction.\n",
    "    - Lz (float): Length in the z direction.\n",
    "    - local_x_index (int): Index of the local volume in the x direction.\n",
    "    - local_z_index (int): Index of the local volume in the z direction.\n",
    "    \"\"\"\n",
    "    # Calculate the boundaries of the specified local volume\n",
    "    step_x = Lx / n\n",
    "    step_z = Lz / m\n",
    "    local_x_min = local_x_index * step_x\n",
    "    local_x_max = (local_x_index + 1) * step_x\n",
    "    local_z_min = local_z_index * step_z\n",
    "    local_z_max = (local_z_index + 1) * step_z\n",
    "\n",
    "    # Filter points within this local volume\n",
    "    local_points = df[\n",
    "        (df[\"x\"] >= local_x_min)\n",
    "        & (df[\"x\"] <= local_x_max)\n",
    "        & (df[\"z\"] >= local_z_min)\n",
    "        & (df[\"z\"] <= local_z_max)\n",
    "    ]\n",
    "\n",
    "    # Create a figure with plotly\n",
    "    fig = make_subplots(rows=1, cols=1, specs=[[{\"type\": \"scatter3d\"}]])\n",
    "\n",
    "    # Filter points where Q is True within the global volume\n",
    "    global_points_true = df[df[\"Q\"]]\n",
    "\n",
    "    # Filter points where Q is True and False within the local volume\n",
    "    local_points_true = local_points[local_points[\"Q\"]]\n",
    "    \n",
    "    if switch_y_z:\n",
    "        # Add scatter plot for points where Q is True in the global volume\n",
    "        trace_global_true = go.Scatter3d(\n",
    "            x=global_points_true[\"x\"],\n",
    "            y=global_points_true[\n",
    "                \"z\"\n",
    "            ],  # switch y and z points to get better default orientation\n",
    "            z=global_points_true[\"y\"],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=3, color=\"red\", opacity=0.5),  # marker color  # marker opacity\n",
    "            name=\"Q=True (Global)\",\n",
    "        )\n",
    "\n",
    "        # Add scatter plot for points where Q is True in the local volume\n",
    "        trace_local_true = go.Scatter3d(\n",
    "            x=local_points_true[\"x\"],\n",
    "            y=local_points_true[\n",
    "                \"z\"\n",
    "            ],  # switch y and z points to get better default orientation\n",
    "            z=local_points_true[\"y\"],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                size=5, color=\"yellow\", opacity=0.8  # marker color  # marker opacity\n",
    "            ),\n",
    "            name=\"Q=True (Local)\",\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        # Add scatter plot for points where Q is True in the global volume\n",
    "        trace_global_true = go.Scatter3d(\n",
    "            x=global_points_true[\"x\"],\n",
    "            y=global_points_true[\"y\"],\n",
    "            z=global_points_true[\"z\"],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(size=3, color=\"red\", opacity=0.5),  # marker color  # marker opacity\n",
    "            name=\"Q=True (Global)\",\n",
    "        )\n",
    "\n",
    "        # Add scatter plot for points where Q is True in the local volume\n",
    "        trace_local_true = go.Scatter3d(\n",
    "            x=local_points_true[\"x\"],\n",
    "            y=local_points_true[\"y\"],\n",
    "            z=local_points_true[\"z\"],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(\n",
    "                size=5, color=\"yellow\", opacity=0.8  # marker color  # marker opacity\n",
    "            ),\n",
    "            name=\"Q=True (Local)\",\n",
    "        )\n",
    "\n",
    "    # Add traces to the figure\n",
    "    fig.add_trace(trace_global_true, row=1, col=1)\n",
    "    fig.add_trace(trace_local_true, row=1, col=1)\n",
    "\n",
    "    # Create a wireframe of the local volume\n",
    "    if switch_y_z:\n",
    "        volume_outline = [\n",
    "            # Bottom face\n",
    "            [local_x_min, local_x_max, local_x_max, local_x_min, local_x_min, local_x_min],\n",
    "            [local_z_min, local_z_min, local_z_max, local_z_max, local_z_min, local_z_min],\n",
    "            [0, 0, 0, 0, 0, 0],  # y values for bottom face\n",
    "            # Top face\n",
    "            [local_x_min, local_x_max, local_x_max, local_x_min, local_x_min, local_x_min],\n",
    "            [local_z_min, local_z_min, local_z_max, local_z_max, local_z_min, local_z_min],\n",
    "            [Ly, Ly, Ly, Ly, Ly, Ly],  # y values for top face\n",
    "            # Vertical lines\n",
    "            [\n",
    "                local_x_min,\n",
    "                local_x_min,\n",
    "                local_x_max,\n",
    "                local_x_max,\n",
    "                local_x_max,\n",
    "                local_x_max,\n",
    "                local_x_min,\n",
    "                local_x_min,\n",
    "            ],\n",
    "            [\n",
    "                local_z_min,\n",
    "                local_z_min,\n",
    "                local_z_min,\n",
    "                local_z_min,\n",
    "                local_z_max,\n",
    "                local_z_max,\n",
    "                local_z_max,\n",
    "                local_z_max,\n",
    "            ],\n",
    "            [0, Ly, 0, Ly, 0, Ly, 0, Ly],  # y values for vertical lines\n",
    "        ]\n",
    "    else:\n",
    "        volume_outline = [\n",
    "            # Bottom face\n",
    "            [local_x_min, local_x_max, local_x_max, local_x_min, local_x_min, local_x_min],\n",
    "            [0, 0, 0, 0, 0, 0],  # y values for bottom face\n",
    "            [local_z_min, local_z_min, local_z_max, local_z_max, local_z_min, local_z_min],\n",
    "            # Top face\n",
    "            [local_x_min, local_x_max, local_x_max, local_x_min, local_x_min, local_x_min],\n",
    "            [Ly, Ly, Ly, Ly, Ly, Ly],  # y values for top face\n",
    "            [local_z_min, local_z_min, local_z_max, local_z_max, local_z_min, local_z_min],\n",
    "            # Vertical lines\n",
    "            [\n",
    "                local_x_min,\n",
    "                local_x_min,\n",
    "                local_x_max,\n",
    "                local_x_max,\n",
    "                local_x_max,\n",
    "                local_x_max,\n",
    "                local_x_min,\n",
    "                local_x_min,\n",
    "            ],\n",
    "            [0, Ly, 0, Ly, 0, Ly, 0, Ly],  # y values for vertical lines\n",
    "            [\n",
    "                local_z_min,\n",
    "                local_z_min,\n",
    "                local_z_min,\n",
    "                local_z_min,\n",
    "                local_z_max,\n",
    "                local_z_max,\n",
    "                local_z_max,\n",
    "                local_z_max,\n",
    "            ],\n",
    "        ]\n",
    "\n",
    "    trace_outline = go.Scatter3d(\n",
    "        x=sum(volume_outline[0::3], []),  # x values\n",
    "        y=sum(volume_outline[1::3], []),  # z values (y axis in plot)\n",
    "        z=sum(volume_outline[2::3], []),  # y values\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"blue\", width=2, dash=\"dot\"),\n",
    "        name=\"Local Volume Outline\",\n",
    "    )\n",
    "\n",
    "    fig.add_trace(trace_outline, row=1, col=1)\n",
    "\n",
    "    # Update layout\n",
    "    if switch_y_z:\n",
    "        fig.update_layout(\n",
    "            title=f\"3D Scatter Plot of Q Events in Local Volume ({local_x_index}, {local_z_index})\",\n",
    "            scene=dict(\n",
    "                xaxis=dict(\n",
    "                    title=\"X Index\",\n",
    "                    range=[0, Lx],  # Normalized range [0, 1]\n",
    "                    tickvals=[i * (Lx / n) for i in range(n + 1)],  # Normalized positions\n",
    "                    ticktext=[str(i) for i in range(n + 1)],  # Custom labels as integers\n",
    "                    showgrid=True,\n",
    "                    gridcolor=\"lightgrey\",\n",
    "                ),\n",
    "                yaxis=dict(\n",
    "                    title=\"Z Index\",\n",
    "                    range=[0, Lz],  # Normalized range [0, 1]\n",
    "                    tickvals=[i* (Lz / m) for i in range(m + 1)],  # Normalized positions\n",
    "                    ticktext=[str(i) for i in range(m + 1)],  # Custom labels as integers\n",
    "                    showgrid=True,\n",
    "                    gridcolor=\"lightgrey\",\n",
    "                ),\n",
    "                zaxis=dict(\n",
    "                    title=\"Y Coordinate\",\n",
    "                    range=[0, Ly],\n",
    "                    showgrid=True,\n",
    "                    gridcolor=\"lightgrey\",\n",
    "                ),\n",
    "            ),\n",
    "            legend_title=\"Legend\",\n",
    "            height=800,\n",
    "            width=1000\n",
    "        )\n",
    "    else:\n",
    "        fig.update_layout(\n",
    "            title=f\"3D Scatter Plot of Q Events in Local Volume ({local_x_index}, {local_z_index})\",\n",
    "            scene=dict(\n",
    "                xaxis=dict(\n",
    "                    title=\"X Index\",\n",
    "                    range=[0, Lx],  # Normalized range [0, 1]\n",
    "                    tickvals=[i * (Lx / n) for i in range(n + 1)],  # Normalized positions\n",
    "                    ticktext=[str(i) for i in range(n + 1)],  # Custom labels as integers\n",
    "                    showgrid=True,\n",
    "                    gridcolor=\"lightgrey\",\n",
    "                ),\n",
    "                yaxis=dict(\n",
    "                    title=\"Y Coordinate\",\n",
    "                    range=[0, Ly],\n",
    "                    showgrid=True,\n",
    "                    gridcolor=\"lightgrey\",\n",
    "                ),\n",
    "                zaxis=dict(\n",
    "                    title=\"Z Index\",\n",
    "                    range=[0, Lz],  # Normalized range [0, 1]\n",
    "                    tickvals=[i * (Lz / m) for i in range(m + 1)],  # Normalized positions\n",
    "                    ticktext=[str(i) for i in range(m + 1)],  # Custom labels as integers\n",
    "                    showgrid=True,\n",
    "                    gridcolor=\"lightgrey\",\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show(renderer=\"browser\")"
   ],
   "id": "f313f56954422a7a",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3c-2. Visualization of local volume Q-events",
   "id": "b4026701d3e8dd91"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T13:00:47.952567Z",
     "start_time": "2024-07-15T13:00:47.553773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "local_x_index = 0  # Index of the local volume in the x direction\n",
    "local_z_index = 1  # Index of the local volume in the z direction\n",
    "\n",
    "if local_x_index > n or local_z_index > m:\n",
    "    raise ValueError(\n",
    "        \"Local volume indices must be within the specified number of sections.\"\n",
    "    )\n",
    "\n",
    "# Timestep of the Q-event to plot\n",
    "num_timestep = 0\n",
    "# The Q-event\n",
    "Q_event_local_plotting = Q_event_frames[num_timestep][1]\n",
    "\n",
    "# Highlight the Q-events in the specified local volume\n",
    "plot_local_Q_events_3d(\n",
    "    Q_event_local_plotting, n, m, Lx, Ly, Lz, local_x_index, local_z_index, switch_y_z=False\n",
    ")"
   ],
   "id": "b6c27b4035e3718a",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. Reward Function",
   "id": "f1890e3101a419bd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Explanation\n",
    "\n",
    "The goal of the reward is to quantify the quality of the local flow field based on the detected Q-events. The reward function should reflect the turbulence intensity and the presence of significant local interactions. The following criteria are currently considered in the reward function:\n",
    "\n",
    "1. **Q-event Density**: The density of Q-events in the local volume, indicating the intensity of local interactions, reflected by `Q_ratio`.\n",
    "\n",
    "Possible future reward options include:\n",
    "\n",
    "2. **Cluster Size**: The size of the largest Q-event cluster, reflecting the spatial extent of significant interactions.\n",
    "3. **Cluster Density**: The density of Q-event clusters, providing insights into the distribution of local interactions.\n",
    "4. **Cluster Connectivity**: The connectivity of Q-event clusters, capturing the coherence of local interactions.\n",
    "5. **Q-event Persistence**: The duration of Q-events, indicating the temporal stability of local interactions.\n",
    "6. **Q-event Intensity**: The intensity of Q-events, reflecting the strength of local interactions.\n",
    "7. **Q-event Diversity**: The variety of Q-event types, capturing different interaction patterns.\n",
    "8. **Q-event Dynamics**: The evolution of Q-events over time, providing insights into local flow dynamics.\n",
    "9. **Q-event Interactions**: The interactions between Q-events, highlighting complex flow structures.\n",
    "10. **Q-event Anomalies**: The presence of unusual or rare Q-events, indicating unique flow characteristics.\n",
    "\n",
    "The current reward function is as follows:\n",
    "\n",
    "`R` = 1 - `Q_ratio`"
   ],
   "id": "8bedaf2c7482ed31"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calculating Reward Based on Q-Ratio",
   "id": "f90fd9b0651c1ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T13:06:15.726072Z",
     "start_time": "2024-07-15T13:06:15.711972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_reward(df: pd.DataFrame, n: int, m: int) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the reward based on the Q ratio in the local volume.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): DataFrame with columns ['x_index', 'z_index', 'Q_ratio'].\n",
    "\n",
    "    Returns:\n",
    "    - float: The calculated reward value.\n",
    "    \"\"\"\n",
    "    # Get specified Q_ratio value based on index\n",
    "    q_ratio = df[(df[\"x_index\"] == n) & (df[\"z_index\"] == m)][\"Q_ratio\"].values[0]\n",
    "    # Calculate the reward based on the Q ratio for the specified index\n",
    "    reward = 1 - q_ratio\n",
    "\n",
    "    return reward"
   ],
   "id": "7cf733d5ffc3eb3e",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T13:06:19.252607Z",
     "start_time": "2024-07-15T13:06:19.243249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "local_x_index = 0  # Index of the local volume in the x direction\n",
    "local_z_index = 0  # Index of the local volume in the z direction\n",
    "\n",
    "# Calculate the reward for the specified local volume\n",
    "reward_value = calculate_reward(timestep_data, local_x_index, local_z_index)\n",
    "\n",
    "# Create a DataFrame with reward value appended to `timestep_data`\n",
    "reward_df = timestep_data.copy()\n",
    "for i in range(n):\n",
    "    for j in range(m):\n",
    "        reward_df.loc[\n",
    "            (reward_df[\"x_index\"] == i) & (reward_df[\"z_index\"] == j), \"reward\"\n",
    "        ] = calculate_reward(timestep_data, i, j)\n",
    "\n",
    "print(reward_df)"
   ],
   "id": "d10b03fc601e9604",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   x_index  z_index  Q_event_count  total_points   Q_ratio    reward\n",
      "0        0        0           1812        115482  0.015691  0.984309\n",
      "1        0        1           3306        120067  0.027535  0.972465\n",
      "2        1        0           3891        121624  0.031992  0.968008\n",
      "3        1        1           3670        124158  0.029559  0.970441\n"
     ]
    }
   ],
   "execution_count": 41
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
